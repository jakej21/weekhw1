{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ee80dc",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54b8cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 391\n",
      "Number of columns: 11\n"
     ]
    }
   ],
   "source": [
    "rows, columns = df.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a6b462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observation indicates individual data or records in dataset. In the context of villagers, it can be each villager and attributes on each row.\n",
    "#variables are characteristics of each observations, which in this case would be personality, birthday and more about villagers shown on columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b98f70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric Column Summary:\n",
      "            row_n\n",
      "count  391.000000\n",
      "mean   239.902813\n",
      "std    140.702672\n",
      "min      2.000000\n",
      "25%    117.500000\n",
      "50%    240.000000\n",
      "75%    363.500000\n",
      "max    483.000000\n",
      "\n",
      "All Columns Summary (including categorical):\n",
      "             row_n       id     name gender species birthday personality  \\\n",
      "count   391.000000      390      391    391     391      391         391   \n",
      "unique         NaN      390      391      2      35      361           8   \n",
      "top            NaN  admiral  Admiral   male     cat     1-27        lazy   \n",
      "freq           NaN        1        1    204      23        2          60   \n",
      "mean    239.902813      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "std     140.702672      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "min       2.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "25%     117.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "50%     240.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "75%     363.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "max     483.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
      "\n",
      "                song   phrase           full_id  \\\n",
      "count            380      391               391   \n",
      "unique            92      388               391   \n",
      "top     K.K. Country  wee one  villager-admiral   \n",
      "freq              10        2                 1   \n",
      "mean             NaN      NaN               NaN   \n",
      "std              NaN      NaN               NaN   \n",
      "min              NaN      NaN               NaN   \n",
      "25%              NaN      NaN               NaN   \n",
      "50%              NaN      NaN               NaN   \n",
      "75%              NaN      NaN               NaN   \n",
      "max              NaN      NaN               NaN   \n",
      "\n",
      "                                                      url  \n",
      "count                                                 391  \n",
      "unique                                                391  \n",
      "top     https://villagerdb.com/images/villagers/thumb/...  \n",
      "freq                                                    1  \n",
      "mean                                                  NaN  \n",
      "std                                                   NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n",
      "\n",
      "Species Count:\n",
      "species\n",
      "cat          23\n",
      "rabbit       20\n",
      "frog         18\n",
      "squirrel     18\n",
      "duck         17\n",
      "dog          16\n",
      "cub          16\n",
      "pig          15\n",
      "bear         15\n",
      "mouse        15\n",
      "horse        15\n",
      "bird         13\n",
      "penguin      13\n",
      "sheep        13\n",
      "elephant     11\n",
      "wolf         11\n",
      "ostrich      10\n",
      "deer         10\n",
      "eagle         9\n",
      "gorilla       9\n",
      "chicken       9\n",
      "koala         9\n",
      "goat          8\n",
      "hamster       8\n",
      "kangaroo      8\n",
      "monkey        8\n",
      "anteater      7\n",
      "hippo         7\n",
      "tiger         7\n",
      "alligator     7\n",
      "lion          7\n",
      "bull          6\n",
      "rhino         6\n",
      "cow           4\n",
      "octopus       3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Personality Type Count:\n",
      "personality\n",
      "lazy      60\n",
      "normal    59\n",
      "cranky    55\n",
      "snooty    55\n",
      "jock      55\n",
      "peppy     49\n",
      "smug      34\n",
      "uchi      24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Summary statistics for numeric columns\n",
    "print(\"Numeric Column Summary:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Summary statistics for all columns (including categorical)\n",
    "print(\"\\nAll Columns Summary (including categorical):\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Count occurrences of each species\n",
    "print(\"\\nSpecies Count:\")\n",
    "print(df['species'].value_counts())\n",
    "\n",
    "# Count occurrences of each personality type\n",
    "print(\"\\nPersonality Type Count:\")\n",
    "print(df['personality'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d985b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality',\n",
      "       'song', 'phrase', 'full_id', 'url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75be043a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(391, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af55fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>species</th>\n",
       "      <th>birthday</th>\n",
       "      <th>personality</th>\n",
       "      <th>song</th>\n",
       "      <th>phrase</th>\n",
       "      <th>full_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "      <td>390</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>380</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390</td>\n",
       "      <td>391</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>361</td>\n",
       "      <td>8</td>\n",
       "      <td>92</td>\n",
       "      <td>388</td>\n",
       "      <td>391</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>admiral</td>\n",
       "      <td>Admiral</td>\n",
       "      <td>male</td>\n",
       "      <td>cat</td>\n",
       "      <td>1-27</td>\n",
       "      <td>lazy</td>\n",
       "      <td>K.K. Country</td>\n",
       "      <td>wee one</td>\n",
       "      <td>villager-admiral</td>\n",
       "      <td>https://villagerdb.com/images/villagers/thumb/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>204</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             row_n       id     name gender species birthday personality  \\\n",
       "count   391.000000      390      391    391     391      391         391   \n",
       "unique         NaN      390      391      2      35      361           8   \n",
       "top            NaN  admiral  Admiral   male     cat     1-27        lazy   \n",
       "freq           NaN        1        1    204      23        2          60   \n",
       "mean    239.902813      NaN      NaN    NaN     NaN      NaN         NaN   \n",
       "std     140.702672      NaN      NaN    NaN     NaN      NaN         NaN   \n",
       "min       2.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
       "25%     117.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
       "50%     240.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
       "75%     363.500000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
       "max     483.000000      NaN      NaN    NaN     NaN      NaN         NaN   \n",
       "\n",
       "                song   phrase           full_id  \\\n",
       "count            380      391               391   \n",
       "unique            92      388               391   \n",
       "top     K.K. Country  wee one  villager-admiral   \n",
       "freq              10        2                 1   \n",
       "mean             NaN      NaN               NaN   \n",
       "std              NaN      NaN               NaN   \n",
       "min              NaN      NaN               NaN   \n",
       "25%              NaN      NaN               NaN   \n",
       "50%              NaN      NaN               NaN   \n",
       "75%              NaN      NaN               NaN   \n",
       "max              NaN      NaN               NaN   \n",
       "\n",
       "                                                      url  \n",
       "count                                                 391  \n",
       "unique                                                391  \n",
       "top     https://villagerdb.com/images/villagers/thumb/...  \n",
       "freq                                                    1  \n",
       "mean                                                  NaN  \n",
       "std                                                   NaN  \n",
       "min                                                   NaN  \n",
       "25%                                                   NaN  \n",
       "50%                                                   NaN  \n",
       "75%                                                   NaN  \n",
       "max                                                   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe88d2",
   "metadata": {},
   "source": [
    "df.shape returns the total size of the dataset. It includes all columns, both numeric and non-numeric. By default, df.describe() only analyzes numeric columns. So, even if there are non-numeric columns, these are excluded from the summary statistics unless you specify include='all'. the number of columns summarized by df.describe() when called without parameters is often fewer than the total number of columns in the dataset, which explains the discrepancy in columns analyzed between df.shape and df.describe(). The total number of rows from df.shape[0] gives the number of observations in the dataset, including rows with missing values. In the \"count\" column of df.describe(), it reports the number of non-missing values for each numeric column. If there are any missing (NaN) values in a column, the \"count\" for that column will be less than the total number of rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd00d30b",
   "metadata": {},
   "source": [
    "An attribute indicates a characteristic that includes the direct information, without going through performance just like df.shape gives the dimensions of the DataFrame. It does not need to take parentheses.\n",
    "A method has particular operation that can be performed on an object, and it takes parentheses because it's a function like df.describe() that gives summary statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7857601",
   "metadata": {},
   "source": [
    "Summary of Interactions (Link to chatlogue) >> https://chatgpt.com/share/70f640aa-54e2-4a1d-9f36-557b650b720a\n",
    "\n",
    "Initial Dataset Loading and Missing Values\n",
    "\n",
    "User's Request: Provided initial code to load a dataset of villagers using pandas and check for missing values:\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n",
    "Assistant's Response: Explained each part of the code, including importing pandas, reading the CSV file into a DataFrame, and using df.isna().sum() to identify missing values in each column. Offered further assistance with interpreting results or data analysis.\n",
    "Printing Number of Rows and Columns\n",
    "\n",
    "User's Request: Asked for code to print the number of rows and columns in the dataset.\n",
    "Assistant's Response: Provided code using df.shape to obtain the dataset dimensions:\n",
    "python\n",
    "Copy code\n",
    "rows, columns = df.shape\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")\n",
    "Explained that df.shape returns a tuple with the number of rows and columns.\n",
    "Understanding Observations and Variables\n",
    "\n",
    "User's Request: Sought clarification on the meanings of \"observations\" and \"variables\" in the dataset context.\n",
    "Assistant's Response: Explained that:\n",
    "Observations correspond to rows in the DataFrame, representing individual data points (e.g., each villager).\n",
    "Variables correspond to columns, representing attributes or features describing each observation (e.g., name, species).\n",
    "Using df.describe() and df['column'].value_counts()\n",
    "\n",
    "User's Request: Requested help in creating examples using df.describe() and df['column'].value_counts(), noting that value_counts() is more suitable for non-numeric variables.\n",
    "Assistant's Response: Provided examples and explanations:\n",
    "Used df.describe() to obtain summary statistics for numeric columns.\n",
    "Used df['species'].value_counts() and df['personality'].value_counts() to count occurrences of each category in categorical columns.\n",
    "Included code snippets and clarified that value_counts() is most informative for categorical data.\n",
    "Summarizing Dataset Columns\n",
    "\n",
    "User's Request: Asked for simple summaries of the dataset columns and code to generate these summaries.\n",
    "Assistant's Response: Summarized key columns such as name, species, personality, birthday, etc. Provided code to:\n",
    "Generate summary statistics using df.describe() and df.describe(include='all').\n",
    "Count occurrences in categorical columns using value_counts().\n",
    "Included examples for species, personality, and sign.\n",
    "Handling KeyError Exception\n",
    "\n",
    "User's Issue: Encountered a KeyError: 'sign' when attempting to access the 'sign' column.\n",
    "Assistant's Response: Explained that the error indicates the 'sign' column does not exist in the dataset. Suggested:\n",
    "Printing the available column names using print(df.columns).\n",
    "Verifying the correct column names and updating the code accordingly.\n",
    "Provided revised code focusing on existing columns like species and personality.\n",
    "Understanding Discrepancies Between df.shape and df.describe()\n",
    "\n",
    "User's Request: Asked for an explanation of discrepancies between df.shape and df.describe() regarding:\n",
    "The number of columns analyzed.\n",
    "The values reported in the \"count\" row, especially with non-numeric variables and missing values in numeric variables.\n",
    "Assistant's Response: Clarified that:\n",
    "df.shape reports the total number of rows and columns, including all variables.\n",
    "df.describe() by default only analyzes numeric columns, excluding non-numeric ones unless include='all' is specified.\n",
    "The \"count\" in df.describe() reflects the number of non-missing values in each column, which may be less than the total number of rows if there are missing values.\n",
    "Provided an illustrative example to demonstrate these points.\n",
    "Difference Between Attributes and Methods\n",
    "\n",
    "User's Request: Asked for help understanding the difference between an \"attribute\" (e.g., df.shape) and a \"method\" (e.g., df.describe()), and requested a paraphrased summary.\n",
    "Assistant's Response: Explained that:\n",
    "An attribute is a property of an object that provides information and is accessed without parentheses (e.g., df.shape gives the DataFrame's dimensions).\n",
    "A method is a function associated with an object that performs an action and requires parentheses (e.g., df.describe() computes summary statistics).\n",
    "Paraphrased summary:\n",
    "Attributes are data or properties of an object; methods are functions that perform actions on the object.\n",
    "Request for Summary of Exchanges\n",
    "\n",
    "User's Request: Asked for a summary of the interactions to submit as part of a homework assignment.\n",
    "Assistant's Response: Provided a detailed summary of the conversation, outlining each topic discussed and the assistance provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf99f410",
   "metadata": {},
   "source": [
    "count is the total number of valid (non-missing) observations for the variable. Missing values (NaN) are excluded from the count. Therefore, df.describe() only counts the non-missing data points.\n",
    "Mean gives the central tendency of the data by calculating the sum of all non-missing values divided by the number of non-missing values.\n",
    "Standard deviation shows how much the values deviate from the mean, indicating variability in the dataset.\n",
    "Min represents the minimum or smallest value in the column.\n",
    "25% (First Quartile) is the value below which 25% of the non-missing data falls.\n",
    "50% (Median) divides the data into two halves, giving the middle value of the dataset.\n",
    "75% (Third Quartile) marks the third quartile or upper quartile, giving an idea of the spread of the upper 75% of data.\n",
    "Max represents the highest observed value among the non-missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9fdcc3",
   "metadata": {},
   "source": [
    "1 - df.dropna() is preferred over del df['col'] when the missing values are scattered over multiple columns but just a few rows are influenced. It's helpful when you want to remove just the incomplete rows as it leaves the rest unchanged. \n",
    "2 - del df['col'] is Preferred over df.dropna() when there is a particular column that has a lot of missing values and is not as important for analysis as a whole. Then this method gets rid of the entire column. \n",
    "3 - We can guarantee to not drop the rows for the missing data of a column by first dropping columns that have significant number of missing value but not important for analysis. We can prevent sacrificing the entire row for just that column. If we apply dropna after the column removal, it gets more efficient as we cut off rows with missing value under important columns and keep much more rows needed for better analysis.\n",
    "4 - before: I see there are 11 data missing on the song column and I judge the column is not very important for the full analysis, so I am getting rid of it with df['col']. Then there will only be one missing data, which I can apply dropna on that particular row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695af97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "del df['song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a71173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0bfe6a",
   "metadata": {},
   "source": [
    "By removing song column and then cleared up the one more row with missing value, now the dataframe does not have any missing value left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380fa46a",
   "metadata": {},
   "source": [
    "summary for chatbot session >>> https://chatgpt.com/share/0536bc48-3849-4bb6-b128-b62cc904b46c\n",
    "In this session, we explored how to handle missing data in a dataset using methods like df.describe(), df.dropna(), and del df['col']. We discussed how df.describe() calculates summary statistics while ignoring missing values, and how different methods can efficiently remove or handle missing data.\n",
    "\n",
    "Key points covered:\n",
    "\n",
    "df.describe() computes summary statistics for numeric columns, ignoring missing data while providing meaningful statistics.\n",
    "df.dropna() is useful for removing rows with missing data, while del df['col'] is ideal for removing columns with excessive missingness.\n",
    "Combining both methods ensures optimal data retention by removing irrelevant columns before dropping rows.\n",
    "We reviewed examples demonstrating when to prefer one method over the other and the rationale for using both together.\n",
    "Lastly, an example was provided showing how to clean a dataset, including a \"before and after\" comparison of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b1af7",
   "metadata": {},
   "source": [
    "df.groupby(\"col1\")[\"col2\"].describe() is two separate function where first component groupby() takes a column from user then group the same answer categories. Next component, as well, takes another column and list the summary of statistics for each group. For example from the titanic file, groupby(\"alone\")[\"age\"].describe() would first differentiate rows by true/false then get sumamry of statistics of age in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9523ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69978c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       count       mean        std   min   25%   50%   75%   max\n",
      "alone                                                           \n",
      "False  310.0  26.413452  15.834923  0.42  16.0  26.0  37.0  70.0\n",
      "True   404.0  32.220297  12.899871  5.00  22.0  29.5  39.0  80.0\n"
     ]
    }
   ],
   "source": [
    "age_stats_by_alone = df.groupby(\"alone\")[\"age\"].describe()\n",
    "print(age_stats_by_alone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea211e6",
   "metadata": {},
   "source": [
    "For df.describe(), count shows how many missing values there are in the entire column. Meanwhile, df.groupby(\"col1\")[\"col2\"].describe() groups unique value in col1 first, then the count of col2 show statistics of each group. In other words, the prior depends on general missingness whie the latter does by groupings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a4d16a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the Titanic dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(url)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset without import\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0169b3",
   "metadata": {},
   "source": [
    "it was faster to use chatgpt to fix the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1e028f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'titanics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Load the Titanic dataset without import\u001b[39;00m\n\u001b[1;32m      3\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitanics.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanics.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the Titanic dataset without import\n",
    "url = \"titanics.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6320f034",
   "metadata": {},
   "source": [
    "It took less using google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd21f56e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mDF\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malone\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "DF.groupby(\"alone\")[\"sex\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea7b1a",
   "metadata": {},
   "source": [
    "Easier using chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b95e1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1974001384.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    df = pd.read_csv(url\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f7836f",
   "metadata": {},
   "source": [
    "Easier using chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d2441a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'group_by'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_53/248148998.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"col2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"col1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"col2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescrible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6200\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'group_by'"
     ]
    }
   ],
   "source": [
    "df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86ecd49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Alone'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAlone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/frame.py:8869\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8866\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   8867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 8869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8872\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8875\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8876\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8878\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8879\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/groupby.py:1278\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/core/groupby/grouper.py:1009\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1007\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1009\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Alone'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.groupby(\"Alone\")[\"sex\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e25e509e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alone' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(url)\n\u001b[0;32m----> 6\u001b[0m df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[43malone\u001b[49m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'alone' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.groupby(alone)[\"sex\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e67eb",
   "metadata": {},
   "source": [
    "Q9 - yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2142a05",
   "metadata": {},
   "source": [
    "Summary >> https://chatgpt.com/share/66e3ab13-7a4c-8005-9b4f-8a2318766c30\n",
    "In this session, you sought help with various Python errors and operations while working on the Titanic dataset. Here's a summary of what we covered:\n",
    "\n",
    "Understanding df.groupby(\"col1\")[\"col2\"].describe(): We explained how this operation groups data by one column and then provides summary statistics for another column within each group.\n",
    "\n",
    "Common Python Errors:\n",
    "\n",
    "NameError: name 'pd' is not defined: Fixed by ensuring the pandas library is imported (import pandas as pd).\n",
    "FileNotFoundError: [Errno 2] No such file or directory: Occurs when the file path is incorrect. We ensured the correct file path or URL is used.\n",
    "NameError: name 'DF' is not defined: Resolved by using consistent casing for variable names (e.g., df instead of DF).\n",
    "SyntaxError: incomplete input: This error is caused by unfinished code. We covered how to complete code to avoid it.\n",
    "AttributeError: 'DataFrame' object has no attribute 'group_by': Corrected by using groupby instead of group_by.\n",
    "KeyError: 'Alone': Occurs when trying to access a non-existent column. We discussed how to create the 'Alone' column if it doesn't exist.\n",
    "NameError: name 'alone' is not defined: Fixed by ensuring column names are referenced correctly (e.g., df['Alone']).\n",
    "This helped you troubleshoot various coding errors and better understand pandas operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3ece9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
